{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Chatbot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-IR6uOAWRlN"
      },
      "source": [
        "# stemming 詞幹提取\n",
        "# lemmatization　詞形還原"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3ZBvN935jAG",
        "outputId": "e5cb1b3a-dabe-46b4-c7f8-5887bec1c991"
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 20 07:52:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt-vsMlVV_Gb",
        "outputId": "ab526a29-67ee-49fe-af7e-03ef60dc9996"
      },
      "source": [
        "from google.colab import drive # Import a library named google.colab\n",
        "drive.mount('/content/drive', force_remount=True) # mount the content to the directory `/content/drive`\n",
        "\n",
        "%cd /content/drive/MyDrive/Tensorflow_Practice\n",
        "# !mkdir HW13     # I HAVE MADE IT. "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Tensorflow_Practice\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yxFaENBV_JA"
      },
      "source": [
        "import nltk # Natural Language Toolkit\n",
        "from nltk.stem.lancaster import LancasterStemmer \n",
        "stemmer = LancasterStemmer()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlP322FRc7dy",
        "outputId": "04850687-cfb5-4f6f-84b0-2ffa079f08b3"
      },
      "source": [
        "!pip install tflearn\n",
        "print(\"tflearn install done\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 107 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=8c7e3c84fabb001370ac55dbd8d7f0134f03a05bb5fa4b0314165f43a7b8dd06\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n",
            "tflearn install done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFRpBuDXWjIG",
        "outputId": "13860e69-7516-4ace-b4a5-2cdb82b95993"
      },
      "source": [
        "import numpy as np\n",
        "import tflearn \n",
        "import tensorflow as tf\n",
        "import random\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Ww32kp0_d1",
        "outputId": "922cabd6-1005-4c49-d4ec-d996e4345bd9"
      },
      "source": [
        "with open(\"intents.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "try:\n",
        "    with open(\"data.pickle\", \"rb\") as f:\n",
        "        words, labels, training, output = pickle.load(f)\n",
        "except:\n",
        "    words = []\n",
        "    labels = []\n",
        "    docs_x = []\n",
        "    docs_y = []\n",
        "\n",
        "    for intent in data[\"intents\"]:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            wrds = nltk.word_tokenize(pattern)\n",
        "            words.extend(wrds)\n",
        "            docs_x.append(wrds)\n",
        "            docs_y.append(intent[\"tag\"])\n",
        "\n",
        "        if intent[\"tag\"] not in labels:\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "    words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
        "    words = sorted(list(set(words)))\n",
        "\n",
        "    labels = sorted(labels)\n",
        "\n",
        "    training = [] # means information about the words in the sentence which is represented by one hot encoding\n",
        "    output = []   # means information about tags  \n",
        "\n",
        "    out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "    for x, doc in enumerate(docs_x):\n",
        "        bag = []\n",
        "\n",
        "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
        "\n",
        "        for w in words:\n",
        "            if w in wrds:\n",
        "                bag.append(1)\n",
        "            else:\n",
        "                bag.append(0)\n",
        "\n",
        "        output_row = out_empty[:]\n",
        "        output_row[labels.index(docs_y[x])] = 1\n",
        "\n",
        "        training.append(bag)\n",
        "        output.append(output_row)\n",
        "\n",
        "\n",
        "    training = np.array(training)\n",
        "    output = np.array(output)\n",
        "\n",
        "    with open(\"data.pickle\", \"wb\") as f:\n",
        "        pickle.dump((words, labels, training, output), f)\n",
        "\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "\n",
        "net = tflearn.input_data(shape=[None, len(training[0])])\n",
        "net = tflearn.fully_connected(net, 8) # this equal to dense network\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "model = tflearn.DNN(net)\n",
        "\n",
        "try:\n",
        "    model.load(\"model.tflearn\")\n",
        "except:\n",
        "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "    model.save(\"model.tflearn\")\n",
        "# model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "# model.save(\"model.tflearn\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Tensorflow_Practice/model.tflearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C0vbv_CiKOp"
      },
      "source": [
        "def bag_of_words(s, words):\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "\n",
        "    s_words = nltk.word_tokenize(s)\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == se:\n",
        "                bag[i] = 1\n",
        "            \n",
        "    return np.array(bag)\n",
        "\n",
        "\n",
        "def chat():\n",
        "    print(\"Start talking with the bot (type quit to stop)!\")\n",
        "    while True:\n",
        "        inp = input(\"You: \")\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        results = model.predict([bag_of_words(inp, words)])[0] # to \n",
        "        results_index = np.argmax(results)\n",
        "        tag = labels[results_index] # GET THE TAG \n",
        "\n",
        "        if results[results_index] > 0.7: \n",
        "            for tg in data[\"intents\"]:\n",
        "                if tg['tag'] == tag:\n",
        "                    responses = tg['responses']\n",
        "            print(random.choice(responses)) # choose a response from the json file \n",
        "        else:\n",
        "            print(\"Sorry, I didn't get what you mean.\")\n",
        "            print(\"Try another question?\")\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF_FU_aBiKT1",
        "outputId": "e2256243-2f05-4342-b3b6-5b739aa71bca"
      },
      "source": [
        "chat()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start talking with the bot (type quit to stop)!\n",
            "You: hello\n",
            "Hello!\n",
            "You: when can i contact you ?\n",
            "I am awoke at 6am-10:30pm from Monday-Saturday!\n",
            "You: what do you often do in your leisure time ?\n",
            "I usually play LOL, pianos, cooking, and editing youtube videos in my spare time!\n",
            "You: what is your name ?\n",
            "I'm twisted_fate aka 資工系的斜槓人生.\n",
            "You: how old are you ?\n",
            "19 years young!\n",
            "You: I'd like to buy something\n",
            "Western style clothes will be my favorite.\n",
            "You: thank you and goodbye ~\n",
            "Sad to see you go :(\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}